{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeeye(sourcepath,savename,date,stt):\n",
    "    import cv2, dlib\n",
    "    import numpy as np\n",
    "    from imutils import face_utils\n",
    "    from keras.models import load_model\n",
    "    import moviepy.editor as mpe\n",
    "    import subprocess\n",
    "    import pandas as pd\n",
    "    \n",
    "    IMG_SIZE = (34, 26)\n",
    "    \n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('model/shape_predictor_68_face_landmarks.dat')\n",
    "    \n",
    "    model = load_model('model/videoopencv.h5')\n",
    "    #model.summary()\n",
    "    \n",
    "    def crop_eye(img, eye_points):\n",
    "        x1, y1 = np.amin(eye_points, axis=0)\n",
    "        x2, y2 = np.amax(eye_points, axis=0)\n",
    "        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "        w = (x2 - x1) * 1.2\n",
    "        h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "        margin_x, margin_y = w / 2, h / 2\n",
    "        min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "        max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "        eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "        eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "        return eye_img, eye_rect\n",
    "    \n",
    "    def get_mspec(movie):\n",
    "        length = int(movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        width = int(movie.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(movie.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = movie.get(cv2.CAP_PROP_FPS)\n",
    "        return length, width, height, fps\n",
    "    \n",
    "    def convert_video(video_input, video_output):\n",
    "        cmds = ['ffmpeg', '-i', video_input, '-r', '24', video_output]\n",
    "        p = subprocess.Popen(cmds, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        stdout, stderr = p.communicate()\n",
    "        return stdout, stderr\n",
    "    \n",
    "    # main\n",
    "    \n",
    "    # 눈깜빡임 수를 담을 변수\n",
    "    frame_counter = 1\n",
    "    frame_index = []\n",
    "    blink_counter = 0\n",
    "    blink_check = True\n",
    "    blinking = 0\n",
    "    \n",
    "    #영상파일 이름\n",
    "    video_input = sourcepath\n",
    "    video_output = \"result/\"+savename+date+'/'+savename+date+'24fps.mp4'\n",
    "    resultpath = \"result/\"+savename+date+'/'+savename+date+'24fps_result.mp4'\n",
    "    \n",
    "    convert_video(video_input, video_output)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_output)\n",
    "    cap_length, cap_width, cap_height, cap_fps_n = get_mspec(cap)\n",
    "    print(cap_length, cap_width, cap_height, cap_fps_n)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(resultpath, fourcc, cap_fps_n, (cap_width//2, cap_height//2))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        \n",
    "        ret, img_ori = cap.read()\n",
    "        \n",
    "        #frame이 정상적으로 받아지는지 체크\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        # frame resizing\n",
    "        img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "        img = img_ori.copy()\n",
    "        \n",
    "        if frame_counter==1:\n",
    "            img_with_box=img\n",
    "    \n",
    "        # 분석할 프래임 선택 작업 (둘 중에 1개 분석하지 않음)\n",
    "        if frame_counter%2!=0:\n",
    "        \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = detector(gray)\n",
    "    \n",
    "            for face in faces:\n",
    "                shapes = predictor(gray, face)\n",
    "                shapes = face_utils.shape_to_np(shapes)\n",
    "    \n",
    "                eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "                eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "    \n",
    "                eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "                eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "                eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "    \n",
    "    #            cv2.imshow('lefteye', eye_img_l)\n",
    "    #            cv2.imshow('righteye', eye_img_r)\n",
    "    \n",
    "                eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "                eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    \n",
    "                pred_l = model.predict(eye_input_l)\n",
    "                pred_r = model.predict(eye_input_r)\n",
    "    \n",
    "                # visualize\n",
    "                CNST = 0.01\n",
    "                state_l = 'O %.1f' if pred_l > CNST else '- %.1f'\n",
    "                state_r = 'O %.1f' if pred_r > CNST else '- %.1f'\n",
    "    \n",
    "                if pred_l < CNST and pred_r < CNST:\n",
    "                    blinking = 1\n",
    "                    if blink_check:\n",
    "                        blink_check=False\n",
    "                        blink_counter += 1\n",
    "                else:\n",
    "                    blinking = 0\n",
    "                    blink_check=True\n",
    "    \n",
    "                state_l = state_l % pred_l\n",
    "                state_r = state_r % pred_r\n",
    "    \n",
    "                cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,0), thickness=1)\n",
    "                cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,0), thickness=1)\n",
    "    \n",
    "                cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255,255,255), 1)\n",
    "                cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255,255,255), 1)\n",
    "    \n",
    "                img_with_box = img.copy()\n",
    "                # for문 끝\n",
    "            #>>> 선택된 프래임 분석 작업 끝\n",
    "        # if문 끝\n",
    "            \n",
    "        #프래임 저장 및 출력\n",
    "        frame_index.append([frame_counter, pred_l, pred_r])\n",
    "        video.write(img_with_box)\n",
    "        #cv2.imshow('result', img_with_box) # 분석과정 화면에 출력\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'): # 분석 중 'q' 키를 누르면 분석을 멈춤.\n",
    "            break\n",
    "        \n",
    "        frame_counter += 1\n",
    "    # while문 끝\n",
    "    \n",
    "    # 모두 닫기\n",
    "    cap.release()\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    arr = np.array(frame_index)\n",
    "    from matplotlib import font_manager, rc\n",
    "    font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "    rc('font', family=font_name)\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    resultlist = []\n",
    "    for i in range(0,len(arr)//24):\n",
    "        left = 0\n",
    "        right = 0\n",
    "        for j in range(i*24,(i+1)*24):\n",
    "            left = left+arr[j,1]\n",
    "            right = right+arr[j,2]\n",
    "        resultlist.append([j,left/24,right/24])\n",
    "    resultarr = np.array(resultlist)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(30, 8))\n",
    "    plt.title('눈 깜박임 차트',fontdict = {'fontsize' : 50})\n",
    "    plt.plot(resultarr[:,1])\n",
    "    plt.plot(resultarr[:,2])\n",
    "    \n",
    "    stt = pd.DataFrame(stt,columns=['word','start','end'])\n",
    "    df = pd.DataFrame(range(1,len(resultarr)+1),columns=['time'])\n",
    "    df['str'] = ''\n",
    "    for i in range(0,len(stt)):\n",
    "        df['str'][df['time']==stt.loc[i,'start'].astype(int)] = df['str'][df['time']==stt.loc[i,'start'].astype(int)] + stt.loc[i,'word'] \n",
    "    s = np.pi/4\n",
    "    n = -1\n",
    "    for i in range(0,len(df)):\n",
    "        s = s+np.pi/4\n",
    "        n = n*-1\n",
    "        yp = resultarr[i,int(1.5+n*0.5)] -0.03+np.sin(s)*0.03\n",
    "        if (yp<0):\n",
    "            yp = 0.01\n",
    "        if (yp>1):\n",
    "            yp = 0.095\n",
    "        plt.text(i-0.5,yp ,df['str'][i],fontdict={'fontsize':12})\n",
    "    \n",
    "    plt.title('눈 떨림 분석 차트',fontdict = {'fontsize' : 50})\n",
    "    plt.legend(['Left Eye','Right Eye'],loc='best')\n",
    "    plt.xlabel('값이 0에 가까울수록 눈을 깜박임', fontdict={'fontsize':20})\n",
    "    plt.savefig(\"result/\"+savename+date+'/'+savename+date+'eyegraph.png')\n",
    "    print(\"eye graph saved in \"+\"result/\"+savename+date+'/'+savename+date+'eyegraph.png')\n",
    "    \n",
    "#    result_cap = cv2.VideoCapture(resultpath)\n",
    "#    result_cap_length, result_cap_width, result_cap_height, result_cap_fps_n = get_mspec(result_cap)\n",
    "#    print(result_cap_length, result_cap_width, result_cap_height, result_cap_fps_n)\n",
    "#    result_cap.release()\n",
    "#    \n",
    "#    # sync를 위한 fps 계산\n",
    "#    duration = cap_length/cap_fps_n\n",
    "#    final_fps_n=result_cap_length/duration\n",
    "#    \n",
    "#    # 중간 비디오클립의 ftp 맞추기\n",
    "#    videoclip = mpe.VideoFileClip(resultpath)\n",
    "#    orig_clip = mpe.VideoFileClip(video_output)\n",
    "#    audioclip = orig_clip.audio\n",
    "#    final_clip = videoclip.set_audio(audioclip)\n",
    "#    final_clip.write_videofile(\"result/\"+savename+date+'/'+savename+date+'eyevideo.mp4')\n",
    "#    print(\"eye video saved in \"+\"result/\"+savename+date+'/'+savename+date+'eyevideo.mp4')\n",
    "#    \n",
    "#    import os\n",
    "#    try:\n",
    "#        os.remove('result/'+name+date+'/'+name+'44100.wav')\n",
    "#        os.remove('result/'+name+date+'/'+name+date+'24fps.mp4')\n",
    "#        os.remove('result/'+name+date+'/'+name+date+'24fps_result.mp4')\n",
    "#        os.remove('result/'+name+date+'/'+name+date+'_final.mp4')\n",
    "#    except:\n",
    "#        print('remove error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
